ğŸ•¸ï¸  CORE OBJECTIVE
Build the missing webâ€‘scraping layer for **HMOâ€¯Hunter** so the UI stops showing
â€œError loading propertiesâ€ and instead displays fresh, live listings that satisfy
Nathanâ€¯Fonteijnâ€™s investment rules.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. WHAT THE CLIENT ACTUALLY WANTS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Source: live properties from **PrimeLocation.com** (phaseÂ 1).  
  (Later weâ€™ll plug in Zoopla and Rightmove, but PrimeLocation is essential now.)

â€¢ Automatic filters, applied serverâ€‘side:
  â—»  Floor areaÂ â‰¥Â 90â€¯sqm  
  â—»  Asking priceÂ â‰¤Â Â£500â€¯000  
  â—»  Outside any **Articleâ€¯4 Direction** boundary                  â†’Â GeoJSON supplied  
  â—»  (Optional) attach **yearly profit** using Local Housing Allowance (LHA) caps

â€¢ Search parameters for the end user:
  â€“ UK postcode **or** town name  
  â€“ Radius in km (e.g. 5Â km)  

â€¢ Visible in the React UI:
  â€“ A card per listing with price (green), size badge (blue), â€œNonâ€‘Articleâ€¯4â€
    badge (green), beds/baths, description snippet, and
    **â€œView on PrimeLocationâ€** link.
  â€“ If LHA data attached, show â€œYearlyÂ Profit: Â£NN,NNNâ€.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2. DATA FLOW WE NEED THE SCRAPER TO ACHIEVE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
POST /api/properties/scrape?postcode=B1&radiusKm=5
        â”‚
        â–¼
(1)Â Generate PrimeLocation search URL(s) using postcode & radius
(2)Â Iterate result pages
(3)Â For each card:
     â€¢ Extract link â†’ open detail page if needed
     â€¢ Parse price, size (sqm or convert from sqÂ ft), beds, baths, lat/lon
(4)Â Push raw rows â†’ processor:
     â€¢ Filter by sizeÂ &Â price
     â€¢ Pointâ€‘inâ€‘polygon test against Articleâ€¯4 GeoJSON
     â€¢ Attach LHA profit if postcode â‡¢Â BRMA match found
(5)Â Upsert final rows into SQLite with timestamp
(6)Â Return JSON array to caller
           â–¼
GET /api/properties
           â–¼
React UI renders cards (no more error!)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
3. TECH CONSTRAINTS & FREEDOM
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ‘©â€ğŸ’»  **Language / libraries** â€“ your call.  
     â€¢ Python + Playwright  *or*  Node + Puppeteer are both fine in Replit.  
     â€¢ Use whatever HTML parser (Cheerio, BeautifulSoup, etc.) you prefer.  
     â€¢ Persist in SQLite for dev; ENVÂ var can point to Postgres later.

ğŸ›‘  **Antiâ€‘blocking mustâ€‘dos**
     â€¢ Identify as â€œHMOâ€‘Hunter/1.0 (+email)â€.  
     â€¢ Max 3 concurrent pages, 2â€‘sec delay between navigations.  
     â€¢ Honour robots.txt; skip disallowed paths.  
     â€¢ Retry w/ exponential backâ€‘off on 429/5xx.

ğŸ“…  **Freshness** â€“ listings in DB should never be older thanÂ 2Â hours.  
     â€¢ Add a cron (nodeâ€‘cron, APScheduler, etc.) to trigger the scraper hourly.

ğŸ”  **Secrets** â€“ read from `process.env.*` (Replit Secrets Manager):
     PRIMELOCATION_COOKIE, ARTICLE4_GEOJSON=/data/Article4.geojson,
     LHA_CSV=/data/lha.csv, DB_PATH

ğŸƒ **Run workflow** â€“ one command triggered by Replitâ€™s **Run** button:
     â€¢ Spin up scraper API on `process.env.PORT`
     â€¢ (Optionally) start React dev server on portÂ 5173 with concurrently  
       Replit will proxy; preview URL must serve the React app.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
4. TEST HOOKS (so we know it works)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# trigger scrape for SW1A 5Â km radius
curl -X POST $REPLIT_URL/api/properties/scrape?postcode=SW1A&radiusKm=5

# should return â‰¥1 JSON row matching the filters
curl $REPLIT_URL/api/properties

If the second call returns a nonâ€‘empty array, the UI will populate without errors.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Deliver this and the project meets the clientâ€™s **essential** requirement:
â€œcollect live PrimeLocation data, filter by 90â€¯sqm / Â£500â€¯k / nonâ€‘Articleâ€¯4,
and show it in the site.â€